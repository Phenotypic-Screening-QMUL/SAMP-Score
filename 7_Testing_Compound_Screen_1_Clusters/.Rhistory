y = trainData_part1$Senescence_Status,
ntree = 500,
type = "classification")
# Make predictions on trainData_part2 using the Random Forest model
rf_predictions_part2 <- predict(rf_model, newdata = trainData_part2)
# Get class probabilities for the positive class
rf_probabilities_part2 <- predict(rf_model, newdata = trainData_part2, type = "prob")[, "Sen"]
# Create the meta-model training data frame
rf_meta_model_data_training <- data.frame(
rf_Prob = as.vector(rf_probabilities_part2),
Senescence_Status = trainData_part2$Senescence_Status,
Predicted_Status = rf_predictions_part2
)
# Save the meta-model training data for further use
write.csv(rf_meta_model_data_training, "rf_meta_model_data_training.csv", row.names = FALSE)
## Now we are going to apply the model to testing data and evaluate
# Make predictions on testing data using the Random Forest model
rf_predictions_test <- predict(rf_model, newdata = combined_testData)
# Get class probabilities for the positive class on testing data
rf_probabilities_test <- predict(rf_model, newdata = combined_testData, type = "prob")[, "Sen"]
# Create the meta-model testing data frame
rf_meta_model_data_testing <- data.frame(
rf_Prob = as.vector(rf_probabilities_test),
Predicted_Status = rf_predictions_test
)
# Save the meta-model testing data for further use
write.csv(rf_meta_model_data_testing, "rf_meta_model_data_testing.csv", row.names = FALSE)
set.seed(123)
# Load required libraries
library(e1071)
library(caret)
library(pROC)
library(ggplot2)
# Ensure Senescence_Status is a factor (for classification)
trainData_part1$Senescence_Status <- as.factor(trainData_part1$Senescence_Status)
trainData_part2$Senescence_Status <- as.factor(trainData_part2$Senescence_Status)
# Prepare training and test data for SVM
x_train <- trainData_part1[, -which(names(trainData_part1) == "Senescence_Status")]
y_train <- trainData_part1$Senescence_Status
x_test <- combined_testData
# Fit the SVM model on trainData_part1
svm_model <- svm(x_train, y_train, kernel = "radial", probability = TRUE)
# Ensure trainData_part2 and combined_testData have the same features as x_train
x_train_part2 <- trainData_part2[, colnames(x_train), drop = FALSE]
# Make predictions on trainData_part2 using the SVM model
svm_predictions_part2 <- predict(svm_model, newdata = x_train_part2, probability = TRUE)
svm_probabilities_part2 <- attr(svm_predictions_part2, "probabilities")[, "Sen"]
svm_predicted_classes_part2 <- ifelse(svm_probabilities_part2 > 0.5, "Sen", "NonSen")
# Create the meta-model training data frame
svm_meta_model_data_training <- data.frame(
svm_Prob = as.vector(svm_probabilities_part2),
Senescence_Status = as.factor(trainData_part2$Senescence_Status),
Predicted_Status = svm_predicted_classes_part2
)
# Save the meta-model training data for further use
write.csv(svm_meta_model_data_training, "svm_meta_model_data_training.csv", row.names = FALSE)
## Now we are going to apply the model to testing data and evaluate
# Make predictions on combined_testData using the SVM model
x_test_combined <- combined_testData
svm_predictions_test <- predict(svm_model, newdata = x_test_combined, probability = TRUE)
svm_probabilities_test <- attr(svm_predictions_test, "probabilities")[, "Sen"]
svm_predicted_classes_test <- ifelse(svm_probabilities_test > 0.5, "Sen", "NonSen")
# Create the meta-model testing data frame
svm_meta_model_data_testing <- data.frame(
svm_Prob = as.vector(svm_probabilities_test),
Predicted_Status = svm_predicted_classes_test
)
# Save the meta-model testing data for further use
write.csv(svm_meta_model_data_testing, "svm_meta_model_data_testing.csv", row.names = FALSE)
set.seed(123)
# Load required libraries
library(mda)
library(caret)
library(pROC)
library(ggplot2)
# Ensure Senescence_Status is a factor (for classification)
trainData_part1$Senescence_Status <- as.factor(trainData_part1$Senescence_Status)
trainData_part2$Senescence_Status <- as.factor(trainData_part2$Senescence_Status)
# Prepare training data for MDA
x_train_part2 <- trainData_part2[, -which(names(trainData_part2) == "Senescence_Status")]
y_train_part2 <- trainData_part2$Senescence_Status
# Fit the MDA model on trainData_part2
mda_model <- mda(Senescence_Status ~ ., data = trainData_part2)
# Ensure test data has the same features as x_train_part2
x_test_combined <- combined_testData
# Make predictions on trainData_part2 using the MDA model
predicted_probabilities_train_mda <- predict(mda_model, newdata = trainData_part2, type = "posterior")
predicted_classes_train_mda <- ifelse(predicted_probabilities_train_mda[, "Sen"] > 0.5, "Sen", "NonSen")
# Create and save the meta-model data frame for trainData_part2
mda_meta_model_training <- data.frame(
mda_Prob = as.vector(predicted_probabilities_train_mda[, "Sen"]),
Senescence_Status = as.factor(trainData_part2$Senescence_Status),
Predicted_Status = predicted_classes_train_mda
)
write.csv(mda_meta_model_training, "mda_meta_model_training.csv", row.names = FALSE)
## Now we are going to apply the model to combined_testData and evaluate
# Make predictions on combined_testData using the MDA model
predicted_probabilities_test_mda <- predict(mda_model, newdata = combined_testData, type = "posterior")
predicted_classes_test_mda <- ifelse(predicted_probabilities_test_mda[, "Sen"] > 0.5, "Sen", "NonSen")
# Create and save the meta-model data frame for combined_testData
mda_meta_model_testing <- data.frame(
mda_Prob = as.vector(predicted_probabilities_test_mda[, "Sen"]),
Predicted_Status = predicted_classes_test_mda
)
write.csv(mda_meta_model_testing, "mda_meta_model_testing.csv", row.names = FALSE)
set.seed(123)
# Load required libraries
library(neuralnet)
library(caret)
library(pROC)
library(ggplot2)
# Prepare the data
Test_Train <- trainData_part1
Test_Test <- trainData_part2
Combined_Test <- combined_testData
# Convert Senescence_Status variable to binary {0, 1}
Test_Train$Senescence_Status <- ifelse(Test_Train$Senescence_Status == "Sen", 1, 0)
Test_Test$Senescence_Status <- ifelse(Test_Test$Senescence_Status == "Sen", 1, 0)
# Define formula for the neural network
formula <- as.formula("Senescence_Status ~ .")
# Train the neural network using trainData_part1
nn_model <- neuralnet(
formula,
data = Test_Train,
hidden = c(20,10,5,2),  # Define the number of neurons in hidden layers
linear.output = FALSE  # Use sigmoid activation function for binary classification
)
# Prepare meta-model training data
x_train_part2 <- Test_Test[, colnames(Test_Train), drop = FALSE]
# Make predictions on Test_Test using the NN model
predicted_probabilities_part2 <- compute(nn_model, as.matrix(x_train_part2[, -which(names(x_train_part2) == "Senescence_Status")]))$net.result
predicted_classes_part2 <- ifelse(predicted_probabilities_part2 > 0.5, 1, 0)
# Create and save the meta-model data frame for Test_Test
nn_meta_model_data_train <- data.frame(
nn_Prob = as.vector(predicted_probabilities_part2),
Senescence_Status = as.factor(Test_Test$Senescence_Status),
Predicted_Status = factor(predicted_classes_part2, levels = c(0, 1), labels = c("NonSen", "Sen"))
)
write.csv(nn_meta_model_data_train, "nn_meta_model_training.csv", row.names = FALSE)
## Now we are going to apply the model to Combined_Test and evaluate
# Make predictions on Combined_Test using the NN model
x_test_combined <- Combined_Test
predicted_probabilities_test <- compute(nn_model, as.matrix(x_test_combined))$net.result
predicted_classes_test <- ifelse(predicted_probabilities_test > 0.5, 1, 0)
# Create and save the meta-model data frame for Combined_Test
nn_meta_model_data_test <- data.frame(
nn_Prob = as.vector(predicted_probabilities_test),
Predicted_Status = factor(predicted_classes_test, levels = c(0, 1), labels = c("NonSen", "Sen"))
)
write.csv(nn_meta_model_data_test, "nn_meta_model_testing.csv", row.names = FALSE)
set.seed(123)
# Combine model predictions and response variable for training
meta_model_data_train <- as.data.frame(cbind(
lasso_meta_model_data_training[,1],
svm_meta_model_data_training[,1],
en_meta_model_data_training[,1],
rf_meta_model_data_training[,1],
mda_meta_model_training[,1],
logistic_meta_model_data_training[,1],
nn_meta_model_data_train[,1:2]
))
colnames(meta_model_data_train) <- c("lasso", "svm", "en", "rf", "mda", "logistic", "nn", "Senescence_Status")
# Extract the predictors and response for training
train_predictors <- meta_model_data_train[, -ncol(meta_model_data_train)]
train_response <- as.factor(meta_model_data_train$Senescence_Status)
# Fit the Lasso model on the training meta-model data
lasso_model <- cv.glmnet(
x = as.matrix(train_predictors),
y = as.numeric(train_response) - 1,  # glmnet requires response to be zero-indexed
family = "binomial",
alpha = 1
)
# Get the best lambda
best_lambda <- lasso_model$lambda.min
# Combine model predictions and response variable for testing
meta_model_data_test <- as.data.frame(cbind(
lasso_meta_model_data_testing[,1],
svm_meta_model_data_testing[,1],
en_meta_model_data_testing[,1],
rf_meta_model_data_testing[,1],
mda_meta_model_testing[,1],
logistic_meta_model_data_testing[,1],
nn_meta_model_data_test[,1:2]
))
colnames(meta_model_data_test) <- c("lasso", "svm", "en", "rf", "mda", "logistic", "nn", "Senescence_Status")
# Extract the predictors and response for testing
test_predictors <- meta_model_data_test[, -ncol(meta_model_data_test)]
test_response <- as.factor(meta_model_data_test$Senescence_Status)
# Make predictions on the meta-model test data using the trained Lasso model
predicted_probabilities_test <- predict(lasso_model, newx = as.matrix(test_predictors), s = best_lambda, type = "response")
predicted_classes_test <- ifelse(predicted_probabilities_test > 0.9, "Sen", "NonSen")
# Combine predictions with the probability into the final data frame
predicted_classes_DDU_Screen <- as.data.frame(cbind(
Indexed_Compounds,
predicted_classes_test,
predicted_probabilities_test,
combined_testData
))
# Rename columns for clarity
colnames(predicted_classes_DDU_Screen)[4:5] <- c("Prediction", "Probability")
# Save the results to a CSV file
write.csv(predicted_classes_DDU_Screen, "DDU_Screen_1_Predictions.csv")
# Logarithmic scatter plot
Log_Scatter_Plot <- ggplot(predicted_classes_DDU_Screen, aes(x = Nuclei.Nuclei.Count.wv1, y = Cells.Area.wv3, color = Prediction)) +
geom_point(size = 0.1) +
scale_y_log10() +
labs(x = "Nuclei Count (Z Score)", y = "Cells Area (Log10 Z Score)", color = "Senescence Prediction") +
theme_bw() +
theme(text = element_text(size = 14))
# Save the plot
ggsave("Log_Scatter_Plot.png", plot = Log_Scatter_Plot, width = 8, height = 6)
# Non-logarithmic scatter plot
Scatter_Plot <- ggplot(predicted_classes_DDU_Screen, aes(x = Nuclei.Nuclei.Count.wv1, y = Cells.Area.wv3, color = Prediction)) +
geom_point(size = 0.1) +
labs(x = "Nuclei Count (Z Score)", y = "Cells Area (Z Score)", color = "Senescence Prediction") +
theme_bw() +
theme(text = element_text(size = 14))
# Save the plot
ggsave("Scatter_Plot.png", plot = Scatter_Plot, width = 8, height = 6)
# Count the total occurrences of each category in Prediction
total_counts <- predicted_classes_DDU_Screen %>%
count(Prediction) %>%
rename(Hit_Count = n)
# Count the occurrences of observations that satisfy the original conditions
conditional_counts_1_92 <- predicted_classes_DDU_Screen %>%
filter(Nuclei.Nuclei.Count.wv1 <= -1.92, Cells.Area.wv3 >= 1.92) %>%
count(Prediction) %>%
rename(Threshold_Count_1_92 = n)
# Count the occurrences of observations that satisfy the stricter conditions (threshold of 3)
conditional_counts_3 <- predicted_classes_DDU_Screen %>%
filter(Nuclei.Nuclei.Count.wv1 <= -3, Cells.Area.wv3 >= 3) %>%
count(Prediction) %>%
rename(Threshold_Count_3 = n)
# Merge the total counts with both sets of conditional counts
merged_counts <- total_counts %>%
left_join(conditional_counts_1_92, by = "Prediction") %>%
left_join(conditional_counts_3, by = "Prediction") %>%
mutate(
Threshold_Count_1_92 = ifelse(is.na(Threshold_Count_1_92), 0, Threshold_Count_1_92),
Threshold_Count_3 = ifelse(is.na(Threshold_Count_3), 0, Threshold_Count_3)
)
# Print the merged counts
print(merged_counts)
write.csv(merged_counts, "Compare_Methods.csv")
# List of identifiers to check
identifiers_to_check <- c("DDD01293078", "DDD01049292")
results <- predicted_classes_DDU_Screen %>%
filter(Compound %in% identifiers_to_check) %>%
mutate(Is_Sen = Prediction == "Sen")  # Check if Prediction is "Sen" and create a new column
# Print the results
print(results)
# Find unique Sen Compounds
# Step 1: Identify compounds that appear as "Sen" only once in the entire dataset
single_sen_compounds <- predicted_classes_DDU_Screen %>%
group_by(Compound) %>%
filter(sum(Prediction == "Sen") == 1) %>%
pull(Compound)  # Extract the list of such compounds
# Step 2: Filter the entire dataset to include only those compounds that are "Sen" only once
final_results <- predicted_classes_DDU_Screen %>%
filter(Compound %in% single_sen_compounds, Prediction == "Sen")
# Print the final results
print(final_results)
write.csv(final_results, "Unique Compounds.csv")
# Create a folder to store the heatmaps if it doesn't already exist
dir.create("Morphology_Heatmaps", showWarnings = FALSE)
# Combine data and add Dose column
Heatmap_Data <- cbind(Indexed_Compounds, predicted_classes_test, combined_testData)
# Add Dose column based on Plate.ID
Heatmap_Data <- Heatmap_Data %>%
mutate(Dose = case_when(
Plate.ID %in% c("Batch_1", "Batch_2", "Batch_5") ~ 10,
Plate.ID %in% c("Batch_3", "Batch_4") ~ 50,
TRUE ~ NA_real_ # In case there are Plate.IDs not listed, assign NA
))
# Remove Plate.ID column and replace with Dose in the data used for heatmaps
Heatmap <- Heatmap_Data[,-which(names(Heatmap_Data) == "Plate.ID")]
# List of unique Dose values and s1 categories
Doses <- unique(Heatmap$Dose)
s1_categories <- unique(Heatmap$s1)
# Loop through each Dose and s1 category to create and save a heatmap
for (dose in Doses) {
for (category in s1_categories) {
# Filter the data for the current Dose and s1 category
Heatmap_adjusted <- Heatmap[Heatmap$Dose == dose & Heatmap$s1 == category, ]
# Set row names to Compound and remove unnecessary columns
rownames(Heatmap_adjusted) <- Heatmap_adjusted$Compound
Heatmap_adjusted <- Heatmap_adjusted[,-c(1,2,3,41)]  # Remove Dose and s1 columns, keep Compound as row names
# Convert to matrix
all_matrix <- as.matrix(Heatmap_adjusted)  # Convert to matrix
# Define color palette and breaks
breaks <- unique(c(seq(-5, -1, length=100), seq(-1, 0.1, length=100), seq(1, 5, length=100)))
my_palette <- colorRampPalette(c("yellow", "black", "black", "purple"))(length(breaks) - 1)
# Save the heatmap as a PNG file
png_filename <- paste0("Morphology_Heatmaps/Heatmap_Dose_", dose, "_", category, ".png")
png(png_filename, width = 800, height = 800)
# Create heatmap
heatmap.2(t(all_matrix),
Rowv = TRUE,
Colv = TRUE,
col = my_palette,
breaks = breaks,
density.info = "none",
trace = "none",
dendrogram = c("both"),
symm = FALSE, symkey = FALSE, symbreaks = TRUE,
labRow = FALSE,
labCol = FALSE,
cexRow = 0.8,
cexCol = 0.1,
margins = c(8, 2),
key.title = "1",
key.xlab = "Z Score",
main = paste("Heatmap for Dose", dose, " - ", category),  # Add a title
sepcolor = c("black"), sepwidth = c(0.05, 0.05),
distfun = function(x) dist(x, method = "euclidean"),
hclust = function(x) hclust(x, method = "ward.D2"))
dev.off()  # Close the PNG device
}
}
library(readxl)
Beth_Hits <- read_excel("DDU Screen 1 Hits.xlsx")
Unique_Hits <- read.csv("Unique Compounds.csv")
Beth_Hits <- Beth_Hits[,1]
Beth_Hits <- Beth_Hits %>% na.omit()
Beth_Hits <- as.vector(Beth_Hits$`DDU Hits`)
Unique_Hits <- as.vector(Unique_Hits$Compound)
## Step 1: Find the intersection of Unique_Hits and Beth_Hits
common_hits <- intersect(Unique_Hits, Beth_Hits)
# Step 2: Calculate the percentage of Beth_Hits that are in Unique_Hits
percentage_overlap <- (length(common_hits) / length(Beth_Hits)) * 100
# Step 3: Print the result
print(paste("Percentage of Beth Hits in Unique Hits:", round(percentage_overlap, 2), "%"))
# Create a folder to store the heatmaps if it doesn't already exist
dir.create("Morphology_Heatmaps", showWarnings = FALSE)
# Combine data and add Dose column
Heatmap_Data <- cbind(Indexed_Compounds, predicted_classes_test, combined_testData)
# Add Dose column based on Plate.ID
Heatmap_Data <- Heatmap_Data %>%
mutate(Dose = case_when(
Plate.ID %in% c("Batch_1", "Batch_2", "Batch_5") ~ 10,
Plate.ID %in% c("Batch_3", "Batch_4") ~ 50,
TRUE ~ NA_real_ # In case there are Plate.IDs not listed, assign NA
))
# Remove Plate.ID column and replace with Dose in the data used for heatmaps
Heatmap <- Heatmap_Data[,-which(names(Heatmap_Data) == "Plate.ID")]
# Set row names to Compound and remove unnecessary columns
rownames(Heatmap) <- Heatmap$Compound
# Create a folder to store the heatmaps if it doesn't already exist
dir.create("Morphology_Heatmaps", showWarnings = FALSE)
# Combine data and add Dose column
Heatmap_Data <- cbind(Indexed_Compounds, predicted_classes_test, combined_testData)
# Add Dose column based on Plate.ID
Heatmap_Data <- Heatmap_Data %>%
mutate(Dose = case_when(
Plate.ID %in% c("Batch_1", "Batch_2", "Batch_5") ~ 10,
Plate.ID %in% c("Batch_3", "Batch_4") ~ 50,
TRUE ~ NA_real_ # In case there are Plate.IDs not listed, assign NA
))
# Remove Plate.ID column and replace with Dose in the data used for heatmaps
Heatmap <- Heatmap_Data[,-which(names(Heatmap_Data) == "Plate.ID")]
# Create unique row names by combining Compound and s1
Heatmap <- Heatmap %>%
mutate(Compound_s1 = paste(Compound, s1, sep = "_"))
# Set row names to the new unique Compound_s1 identifier and remove unnecessary columns
rownames(Heatmap) <- Heatmap$Compound_s1
# Create a folder to store the heatmaps if it doesn't already exist
dir.create("Morphology_Heatmaps", showWarnings = FALSE)
# Combine data and add Dose column
Heatmap_Data <- cbind(Indexed_Compounds, predicted_classes_test, combined_testData)
# Add Dose column based on Plate.ID
Heatmap_Data <- Heatmap_Data %>%
mutate(Dose = case_when(
Plate.ID %in% c("Batch_1", "Batch_2", "Batch_5") ~ 10,
Plate.ID %in% c("Batch_3", "Batch_4") ~ 50,
TRUE ~ NA_real_ # In case there are Plate.IDs not listed, assign NA
))
# Remove Plate.ID column and replace with Dose in the data used for heatmaps
Heatmap <- Heatmap_Data[,-which(names(Heatmap_Data) == "Plate.ID")]
# Create unique row names by combining Compound and Dose
Heatmap <- Heatmap %>%
mutate(Compound_Dose = paste(Compound, Dose, sep = "_"))
# Set row names to the new unique Compound_Dose identifier and remove unnecessary columns
rownames(Heatmap) <- Heatmap$Compound_Dose
Heatmap_adjusted <- Heatmap[,-c(1, 2, 3, 41, ncol(Heatmap))]  # Remove Dose, s1, Compound, and the new Compound_Dose columns
# Convert to matrix
all_matrix <- as.matrix(Heatmap_adjusted)
# Define color palette and breaks
breaks <- unique(c(seq(-5, -1, length=100), seq(-1, 0.1, length=100), seq(1, 5, length=100)))
my_palette <- colorRampPalette(c("yellow", "black", "black", "purple"))(length(breaks) - 1)
# Save the total heatmap as a PNG file
png_filename <- "Morphology_Heatmaps/Total_Heatmap.png"
png(png_filename, width = 800, height = 800)
# Create heatmap
heatmap.2(t(all_matrix),
Rowv = TRUE,
Colv = TRUE,
col = my_palette,
breaks = breaks,
density.info = "none",
trace = "none",
dendrogram = c("both"),
symm = FALSE, symkey = FALSE, symbreaks = TRUE,
labRow = FALSE,
labCol = FALSE,
cexRow = 0.8,
cexCol = 0.1,
margins = c(8, 2),
key.title = "1",
key.xlab = "Z Score",
main = "Total Heatmap for All Doses and Categories",  # Add a title
sepcolor = c("black"), sepwidth = c(0.05, 0.05),
distfun = function(x) dist(x, method = "euclidean"),
hclust = function(x) hclust(x, method = "ward.D2"))
dev.off()  # Close the PNG device
# Create a folder to store the heatmaps if it doesn't already exist
dir.create("Morphology_Heatmaps", showWarnings = FALSE)
# Combine data and add Dose column
Heatmap_Data <- cbind(Indexed_Compounds, predicted_classes_test, combined_testData)
# Add Dose column based on Plate.ID
Heatmap_Data <- Heatmap_Data %>%
mutate(Dose = case_when(
Plate.ID %in% c("Batch_1", "Batch_2", "Batch_5") ~ 10,
Plate.ID %in% c("Batch_3", "Batch_4") ~ 50,
TRUE ~ NA_real_ # In case there are Plate.IDs not listed, assign NA
))
# Remove Plate.ID column and replace with Dose in the data used for heatmaps
Heatmap <- Heatmap_Data[,-which(names(Heatmap_Data) == "Plate.ID")]
# Create unique row names by combining Compound and Dose
Heatmap <- Heatmap %>%
mutate(Compound_Dose = paste(Compound, Dose, sep = "_"))
# Set row names to the new unique Compound_Dose identifier and remove unnecessary columns
rownames(Heatmap) <- Heatmap$Compound_Dose
Heatmap_adjusted <- Heatmap[,-c(1, 2, 3, 41, ncol(Heatmap))]  # Remove Dose, s1, Compound, and the new Compound_Dose columns
# Convert to matrix
all_matrix <- as.matrix(Heatmap_adjusted)
# Define color palette and breaks
breaks <- unique(c(seq(-5, -1, length=100), seq(-1, 0.1, length=100), seq(1, 5, length=100)))
my_palette <- colorRampPalette(c("yellow", "black", "black", "purple"))(length(breaks) - 1)
# Save the total heatmap as a PNG file
png_filename <- "Morphology_Heatmaps/Total_Heatmap.png"
png(png_filename, width = 800, height = 2000)
# Create heatmap
heatmap.2(t(all_matrix),
Rowv = TRUE,
Colv = TRUE,
col = my_palette,
breaks = breaks,
density.info = "none",
trace = "none",
dendrogram = c("both"),
symm = FALSE, symkey = FALSE, symbreaks = TRUE,
labRow = FALSE,
labCol = FALSE,
cexRow = 0.8,
cexCol = 0.1,
margins = c(8, 2),
key.title = "1",
key.xlab = "Z Score",
main = "Total Heatmap for All Doses and Categories",  # Add a title
sepcolor = c("black"), sepwidth = c(0.05, 0.05),
distfun = function(x) dist(x, method = "euclidean"),
hclust = function(x) hclust(x, method = "ward.D2"))
dev.off()  # Close the PNG device
# Create a folder to store the heatmaps if it doesn't already exist
dir.create("Morphology_Heatmaps", showWarnings = FALSE)
# Combine data and add Dose column
Heatmap_Data <- cbind(Indexed_Compounds, predicted_classes_test, combined_testData)
# Add Dose column based on Plate.ID
Heatmap_Data <- Heatmap_Data %>%
mutate(Dose = case_when(
Plate.ID %in% c("Batch_1", "Batch_2", "Batch_5") ~ 10,
Plate.ID %in% c("Batch_3", "Batch_4") ~ 50,
TRUE ~ NA_real_ # In case there are Plate.IDs not listed, assign NA
))
# Remove Plate.ID column and replace with Dose in the data used for heatmaps
Heatmap <- Heatmap_Data[,-which(names(Heatmap_Data) == "Plate.ID")]
# Create unique row names by combining Compound and Dose
Heatmap <- Heatmap %>%
mutate(Compound_Dose = paste(Compound, Dose, sep = "_"))
# Set row names to the new unique Compound_Dose identifier and remove unnecessary columns
rownames(Heatmap) <- Heatmap$Compound_Dose
Heatmap_adjusted <- Heatmap[,-c(1, 2, 3, 41, ncol(Heatmap))]  # Remove Dose, s1, Compound, and the new Compound_Dose columns
# Convert to matrix
all_matrix <- as.matrix(Heatmap_adjusted)
# Define color palette and breaks
breaks <- unique(c(seq(-5, -1, length=100), seq(-1, 0.1, length=100), seq(1, 5, length=100)))
my_palette <- colorRampPalette(c("yellow", "black", "black", "purple"))(length(breaks) - 1)
# Save the total heatmap as a PNG file
png_filename <- "Morphology_Heatmaps/Total_Heatmap.png"
png(png_filename, width = 2000, height = 800)
# Create heatmap
heatmap.2(t(all_matrix),
Rowv = TRUE,
Colv = TRUE,
col = my_palette,
breaks = breaks,
density.info = "none",
trace = "none",
dendrogram = c("both"),
symm = FALSE, symkey = FALSE, symbreaks = TRUE,
labRow = FALSE,
labCol = FALSE,
cexRow = 0.8,
cexCol = 0.1,
margins = c(8, 2),
key.title = "1",
key.xlab = "Z Score",
main = "Total Heatmap for All Doses and Categories",  # Add a title
sepcolor = c("black"), sepwidth = c(0.05, 0.05),
distfun = function(x) dist(x, method = "euclidean"),
hclust = function(x) hclust(x, method = "ward.D2"))
dev.off()  # Close the PNG device

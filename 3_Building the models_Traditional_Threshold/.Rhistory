# Compute ROC curve and AUC for NN
roc_curve_nn <- roc(Combined_Test$Senescence_Status, predicted_probabilities_test)
auc_roc_nn <- auc(roc_curve_nn)
# Calculate Cohen's Kappa
kappa_nn <- nn_confusion_mtx_test$overall["Kappa"]
# Ensure the 'ROCs' directory exists
if (!dir.exists("ROCs")) {
dir.create("ROCs")
}
# Create the ROC plot for NN
roc_plot_nn <- ggroc(roc_curve_nn, legacy.axes = TRUE, alpha = 0.5, colour = "blue", linetype = 1, size = 1) +
labs(title = "ROC Curve on Combined Test Data (Neural Network)", x = "False Positive Rate", y = "True Positive Rate") +
geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), color = "black", linetype = "dashed")
# Save the ROC plot
ggsave("ROCs/roc_curve_nn.png", plot = roc_plot_nn, width = 8, height = 6)
# Store metrics and confusion matrix breakdown for Combined_Test in a data frame
NN_metrics_df_test <- data.frame(
Model = "Neural Network",
Accuracy = nn_confusion_mtx_test$overall["Accuracy"],
Precision = precision_nn,
Recall = recall_nn,
F1_Score = f1_score_nn,
AUC = auc_roc_nn,
Specificity = specificity_nn,
FPR = fpr_nn,
Kappa = kappa_nn,
TP = nn_confusion_mtx_test$table["Sen", "Sen"],
TN = nn_confusion_mtx_test$table["NonSen", "NonSen"],
FN = nn_confusion_mtx_test$table["NonSen", "Sen"],
FP = nn_confusion_mtx_test$table["Sen", "NonSen"]
)
# Save the metrics for Combined_Test to a CSV file
write.csv(NN_metrics_df_test, "neural_network_metrics.csv", row.names = FALSE)
# Custom plot function for neural network
custom_plot_nn <- function(nn_model, plot_title = "Neural Network") {
plot(nn_model, rep = "best",
show.weights = FALSE,
dimension = c(2000, 800),
radius = 3,  # Adjust the radius of the nodes
fontsize = 18,  # Adjust the font size
arrow.length = 0.1,  # Adjust the length of the arrows
information = FALSE,
main = plot_title)
}
# Plot and save the neural network with custom function
plot_name <- "ROCs/neural_network_plot.png"
png(plot_name, width = 2000, height = 1000)
custom_plot_nn(nn_model)
dev.off()
print(roc_plot_nn)
set.seed(123)
# Load required libraries
library(glmnet)
library(caret)
library(pROC)
library(ggplot2)
# Combine model predictions and response variable for training
meta_model_data_train <- as.data.frame(cbind(
lasso_meta_model_data_training[,1],
svm_meta_model_data_training[,1],
en_meta_model_data_training[,1],
rf_meta_model_data_training[,1],
mda_meta_model_training[,1],
logistic_meta_model_data_training[,1],
nn_meta_model_data_train[,1:2]
))
colnames(meta_model_data_train) <- c("lasso", "svm", "en", "rf", "mda", "logistic", "nn", "Senescence_Status")
# Extract the predictors and response for training
train_predictors <- meta_model_data_train[, -ncol(meta_model_data_train)]
train_response <- as.factor(meta_model_data_train$Senescence_Status)
# Fit the Lasso model on the training meta-model data
lasso_model <- cv.glmnet(
x = as.matrix(train_predictors),
y = as.numeric(train_response) - 1,  # glmnet requires response to be zero-indexed
family = "binomial",
alpha = 1
)
# Get the best lambda
best_lambda <- lasso_model$lambda.min
# Combine model predictions and response variable for testing
meta_model_data_test <- as.data.frame(cbind(
lasso_meta_model_data_testing[,1],
svm_meta_model_data_testing[,1],
en_meta_model_data_testing[,1],
rf_meta_model_data_testing[,1],
mda_meta_model_testing[,1],
logistic_meta_model_data_testing[,1],
nn_meta_model_data_test[,1:2]
))
colnames(meta_model_data_test) <- c("lasso", "svm", "en", "rf", "mda", "logistic", "nn", "Senescence_Status")
# Extract the predictors and response for testing
test_predictors <- meta_model_data_test[, -ncol(meta_model_data_test)]
test_response <- as.factor(meta_model_data_test$Senescence_Status)
# Make predictions on the meta-model test data using the trained Lasso model
predicted_probabilities_test <- predict(lasso_model, newx = as.matrix(test_predictors), s = best_lambda, type = "response")
predicted_classes_test <- ifelse(predicted_probabilities_test > 0.5, "1", "0")
# Calculate accuracy for Lasso on the test data
Lasso_accuracy_test <- mean(predicted_classes_test == meta_model_data_test$Senescence_Status)
print(paste("Lasso Accuracy on test data:", Lasso_accuracy_test))
# Prepare the data for confusion matrix
meta_model_data_test$predicted_classes <- factor(predicted_classes_test, levels = c("0", "1"))
# Convert actual classes to factor
meta_model_data_test$Senescence_Status <- factor(meta_model_data_test$Senescence_Status, levels = c("0", "1"))
# Create the confusion matrix for the test data
confusion_mtx_test <- confusionMatrix(data = meta_model_data_test$predicted_classes, reference = meta_model_data_test$Senescence_Status)
print(confusion_mtx_test)
# Calculate additional metrics for the test data
precision_test <- confusion_mtx_test$byClass["Pos Pred Value"]
recall_test <- confusion_mtx_test$byClass["Sensitivity"]
f1_score_test <- confusion_mtx_test$byClass["F1"]
specificity_test <- confusion_mtx_test$byClass["Neg Pred Value"]
fpr_test <- 1 - specificity_test
# Compute ROC curve and AUC for the test data
roc_curve_test <- roc(meta_model_data_test$Senescence_Status, as.numeric(predicted_probabilities_test))
auc_roc_test <- auc(roc_curve_test)
# Calculate Cohen's Kappa for the test data
kappa_test <- confusion_mtx_test$overall["Kappa"]
# Create the ROC plot for the test data
roc_plot_test <- ggroc(roc_curve_test, legacy.axes = TRUE, alpha = 0.5, colour = "blue", linetype = 1, size = 1) +
labs(title = "ROC Curve on Test Data (Meta Model)", x = "False Positive Rate", y = "True Positive Rate") +
geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), color = "black", linetype = "dashed")
# Save the ROC plot for the test data
ggsave("roc_curve_meta_model_test.png", plot = roc_plot_test, width = 8, height = 6)
# Store metrics and confusion matrix breakdown for the test data in a data frame
Meta_metrics_df_test <- data.frame(
Model = "Meta Model",
Accuracy = Lasso_accuracy_test,
Precision = precision_test,
Recall = recall_test,
F1_Score = f1_score_test,
AUC = auc_roc_test,
Specificity = specificity_test,
FPR = fpr_test,
Kappa = kappa_test,
TP = confusion_mtx_test$table["1", "1"],
TN = confusion_mtx_test$table["0", "0"],
FN = confusion_mtx_test$table["0", "1"],
FP = confusion_mtx_test$table["1", "0"]
)
# Save the metrics for the test data to a CSV file
write.csv(Meta_metrics_df_test, "Meta_Model_metrics_test.csv", row.names = FALSE)
# Get the list of CSV files in the working directory
csv_files <- list.files(pattern = "\\.csv$")
# Loop through each CSV file and read it into a data frame
for (file in csv_files) {
# Extract the name of the data frame from the file name
df_name <- sub(".csv$", "", file)
# Read the CSV file into a data frame
assign(df_name, read.csv(file))
}
# Define the desired columns
desired_columns <- c("Model", "Accuracy", "Precision", "Recall", "F1_Score", "AUC", "Specificity", "TP", "TN", "FN", "FP")
# Function to subset data frames to include only desired columns
subset_columns <- function(df, columns) {
# Check if all desired columns are present in the data frame
if (all(columns %in% colnames(df))) {
return(df[, columns, drop = FALSE])
} else {
# Return a message if some columns are missing
warning("Some columns are missing in the data frame")
return(df) # Return the original data frame if columns are missing
}
}
# Subset each data frame to keep only the desired columns
logistic_model_metrics <- subset_columns(logistic_model_metrics, desired_columns)
lasso_model_metrics <- subset_columns(lasso_model_metrics, desired_columns)
svm_model_metrics <- subset_columns(svm_model_metrics, desired_columns)
en_model_metrics <- subset_columns(en_model_metrics, desired_columns)
rf_model_metrics <- subset_columns(rf_model_metrics, desired_columns)
mda_model_metrics <- subset_columns(mda_model_metrics, desired_columns)
neural_network_metrics <- subset_columns(neural_network_metrics, desired_columns)
Meta_Model_metrics <- subset_columns(Meta_Model_metrics_test, desired_columns)
# Combine the subsetted data frames into one data frame
All_Metric <- rbind(
logistic_model_metrics,
lasso_model_metrics,
svm_model_metrics,
en_model_metrics,
rf_model_metrics,
mda_model_metrics,
neural_network_metrics,
Meta_Model_metrics
)
write.csv(All_Metric, "All_Model_Metrics.csv", row.names = FALSE)
# Define a folder to save the heatmaps
output_folder <- "Heatmaps"
if (!dir.exists(output_folder)) {
dir.create(output_folder)
}
# Function to save heatmap to file
save_heatmap <- function(matrix_data, file_name, cellnote_data) {
# Define the file path
file_path <- file.path(output_folder, file_name)
# Open a graphics device to save the plot
png(file_path, width = 800, height = 600)
# Plot heatmap
heatmap.2(matrix_data, Rowv = NA, Colv = NA, dendrogram = "none", trace = "none",
col = rev(colorRampPalette(c("red","white", "turquoise"))(256)), scale = "column", key = TRUE, keysize = 1.5,
key.title = NA, density.info = "none", cexRow = 0.8, cexCol = 0.8,
margins = c(5, 10), cellnote = cellnote_data, notecol = "black")
# Close the graphics device
dev.off()
}
# First Heatmap - Metrics in Percentages
HM_Met <- All_Metric[, -c(1,8:11)]
rownames(HM_Met) <- All_Metric[, 1]
rownames(HM_Met) <- gsub(" \\(Combined Test Data\\)", "", rownames(HM_Met))
HM_Met <- as.matrix(HM_Met)
HM_Met_percent <- HM_Met * 100
HM_Met_percent_rounded <- round(HM_Met_percent, 1)
HM_Met_percent_char <- matrix(paste0(HM_Met_percent_rounded, "%"), nrow = nrow(HM_Met_percent_rounded))
# Save the first heatmap
save_heatmap(HM_Met, "Heatmap_Metrics_Percentages.png", HM_Met_percent_char)
# Second Heatmap - Confusion Matrix Metrics
HM_Met <- All_Metric[, -c(1:7)]
rownames(HM_Met) <- All_Metric[, 1]
rownames(HM_Met) <- gsub(" \\(Combined Test Data\\)", "", rownames(HM_Met))
HM_Met <- as.matrix(HM_Met)
HM_Met <- round(HM_Met, 1)
# Save the second heatmap
save_heatmap(HM_Met, "Heatmap_Confusion_Matrix_Metrics.png", HM_Met)
library("gplots")
library("RColorBrewer")
library("matrixStats")
library("plyr")
library("dplyr")
library("data.table")
library("stringr")
library("ggplot2")
library(glmnet)
library(caret)
library(pROC)
library(e1071)  # Contains functions for SVM
library(randomForest)
library(mda)
library(neuralnet)
# Upload your file
all <- read.csv("All_Z_Scores_Consensus.csv")
library("gplots")
library("RColorBrewer")
library("matrixStats")
library("plyr")
library("dplyr")
library("data.table")
library("stringr")
library("ggplot2")
library(glmnet)
library(caret)
library(pROC)
library(e1071)  # Contains functions for SVM
library(randomForest)
library(mda)
library(neuralnet)
# Upload your file
all <- read.csv("All_Data_Clusters_Consensus.csv")
#Remove Blanks
all_small <- all %>%
filter(!grepl("Blank", Gene.Symbol))
### Sanity check - NA removed in previous stage
all_removed <- all %>%
filter(grepl("Blank", Gene.Symbol))
# Update DF ###
all <- all_small
#Deal with duplicate Gene Entries (12 in total)#
all <- all %>%
group_by(RefSeq.Accession.Number) %>%
mutate(RefSeq.Accession.Number = ifelse(row_number() == 1, RefSeq.Accession.Number, paste0(RefSeq.Accession.Number, "_A")))
#Add Ground Truth - Define filtering criteria
all <- all %>%
mutate(Senescence_Status = ifelse(`Nuclei.Nuclei.Count.wv1` < -1.96 & Cells.Area.wv3 > 1.96, "Sen", "NonSen"))
View(all)
# Get the list of CSV files in the working directory
csv_files <- list.files(pattern = "\\.csv$")
# Loop through each CSV file and read it into a data frame
for (file in csv_files) {
# Extract the name of the data frame from the file name
df_name <- sub(".csv$", "", file)
# Read the CSV file into a data frame
assign(df_name, read.csv(file))
}
# Define the desired columns
desired_columns <- c("Model", "Accuracy", "Precision", "Recall", "F1_Score", "AUC", "Neg_Pred_Value", "TP", "TN", "FN", "FP")
# Function to subset data frames to include only desired columns
subset_columns <- function(df, columns) {
# Check if all desired columns are present in the data frame
if (all(columns %in% colnames(df))) {
return(df[, columns, drop = FALSE])
} else {
# Return a message if some columns are missing
warning("Some columns are missing in the data frame")
return(df) # Return the original data frame if columns are missing
}
}
# Subset each data frame to keep only the desired columns
logistic_model_metrics <- subset_columns(logistic_model_metrics, desired_columns)
lasso_model_metrics <- subset_columns(lasso_model_metrics, desired_columns)
svm_model_metrics <- subset_columns(svm_model_metrics, desired_columns)
en_model_metrics <- subset_columns(en_model_metrics, desired_columns)
rf_model_metrics <- subset_columns(rf_model_metrics, desired_columns)
mda_model_metrics <- subset_columns(mda_model_metrics, desired_columns)
neural_network_metrics <- subset_columns(neural_network_metrics, desired_columns)
Meta_Model_metrics <- subset_columns(Meta_Model_metrics_test, desired_columns)
# Combine the subsetted data frames into one data frame
All_Metric <- rbind(
logistic_model_metrics,
lasso_model_metrics,
svm_model_metrics,
en_model_metrics,
rf_model_metrics,
mda_model_metrics,
neural_network_metrics,
Meta_Model_metrics
)
write.csv(All_Metric, "All_Model_Metrics.csv", row.names = FALSE)
# Define a folder to save the heatmaps
output_folder <- "Heatmaps"
if (!dir.exists(output_folder)) {
dir.create(output_folder)
}
# Function to save heatmap to file
save_heatmap <- function(matrix_data, file_name, cellnote_data) {
# Define the file path
file_path <- file.path(output_folder, file_name)
# Open a graphics device to save the plot
png(file_path, width = 800, height = 600)
# Plot heatmap
heatmap.2(matrix_data, Rowv = NA, Colv = NA, dendrogram = "none", trace = "none",
col = rev(colorRampPalette(c("red","white", "turquoise"))(256)), scale = "column", key = TRUE, keysize = 1.5,
key.title = NA, density.info = "none", cexRow = 0.8, cexCol = 0.8,
margins = c(4, 8), cellnote = cellnote_data, notecol = "black")
# Close the graphics device
dev.off()
}
# First Heatmap - Metrics in Percentages
HM_Met <- All_Metric[, -c(1,8:11)]
rownames(HM_Met) <- All_Metric[, 1]
rownames(HM_Met) <- gsub(" \\(Combined Test Data\\)", "", rownames(HM_Met))
HM_Met <- as.matrix(HM_Met)
HM_Met_percent <- HM_Met * 100
HM_Met_percent_rounded <- round(HM_Met_percent, 1)
HM_Met_percent_char <- matrix(paste0(HM_Met_percent_rounded, "%"), nrow = nrow(HM_Met_percent_rounded))
# Save the first heatmap
save_heatmap(HM_Met, "Heatmap_Metrics_Percentages.png", HM_Met_percent_char)
# Second Heatmap - Confusion Matrix Metrics
HM_Met <- All_Metric[, -c(1:7)]
rownames(HM_Met) <- All_Metric[, 1]
rownames(HM_Met) <- gsub(" \\(Combined Test Data\\)", "", rownames(HM_Met))
HM_Met <- as.matrix(HM_Met)
HM_Met <- round(HM_Met, 1)
# Save the second heatmap
save_heatmap(HM_Met, "Heatmap_Confusion_Matrix_Metrics.png", HM_Met)
# Get the list of CSV files in the working directory
csv_files <- list.files(pattern = "\\.csv$")
# Loop through each CSV file and read it into a data frame
for (file in csv_files) {
# Extract the name of the data frame from the file name
df_name <- sub(".csv$", "", file)
# Read the CSV file into a data frame
assign(df_name, read.csv(file))
}
# Define the desired columns
desired_columns <- c("Model", "Accuracy", "Precision", "Recall", "F1_Score", "AUC", "Neg_Pred_Value", "TP", "TN", "FN", "FP")
# Function to subset data frames to include only desired columns
subset_columns <- function(df, columns) {
# Check if all desired columns are present in the data frame
if (all(columns %in% colnames(df))) {
return(df[, columns, drop = FALSE])
} else {
# Return a message if some columns are missing
warning("Some columns are missing in the data frame")
return(df) # Return the original data frame if columns are missing
}
}
# Subset each data frame to keep only the desired columns
logistic_model_metrics <- subset_columns(logistic_model_metrics, desired_columns)
lasso_model_metrics <- subset_columns(lasso_model_metrics, desired_columns)
svm_model_metrics <- subset_columns(svm_model_metrics, desired_columns)
en_model_metrics <- subset_columns(en_model_metrics, desired_columns)
rf_model_metrics <- subset_columns(rf_model_metrics, desired_columns)
mda_model_metrics <- subset_columns(mda_model_metrics, desired_columns)
neural_network_metrics <- subset_columns(neural_network_metrics, desired_columns)
Meta_Model_metrics <- subset_columns(Meta_Model_metrics_test, desired_columns)
# Combine the subsetted data frames into one data frame
All_Metric <- rbind(
logistic_model_metrics,
lasso_model_metrics,
svm_model_metrics,
en_model_metrics,
rf_model_metrics,
mda_model_metrics,
neural_network_metrics,
Meta_Model_metrics
)
write.csv(All_Metric, "All_Model_Metrics.csv", row.names = FALSE)
# Define a folder to save the heatmaps
output_folder <- "Heatmaps"
if (!dir.exists(output_folder)) {
dir.create(output_folder)
}
# Function to save heatmap to file
save_heatmap <- function(matrix_data, file_name, cellnote_data) {
# Define the file path
file_path <- file.path(output_folder, file_name)
# Open a graphics device to save the plot
png(file_path, width = 800, height = 600)
# Plot heatmap
heatmap.2(matrix_data, Rowv = NA, Colv = NA, dendrogram = "none", trace = "none",
col = rev(colorRampPalette(c("red","white", "turquoise"))(256)), scale = "column", key = TRUE, keysize = 1.5,
key.title = NA, density.info = "none", cexRow = 0.8, cexCol = 0.8,
margins = c(3, 8), cellnote = cellnote_data, notecol = "black")
# Close the graphics device
dev.off()
}
# First Heatmap - Metrics in Percentages
HM_Met <- All_Metric[, -c(1,8:11)]
rownames(HM_Met) <- All_Metric[, 1]
rownames(HM_Met) <- gsub(" \\(Combined Test Data\\)", "", rownames(HM_Met))
HM_Met <- as.matrix(HM_Met)
HM_Met_percent <- HM_Met * 100
HM_Met_percent_rounded <- round(HM_Met_percent, 1)
HM_Met_percent_char <- matrix(paste0(HM_Met_percent_rounded, "%"), nrow = nrow(HM_Met_percent_rounded))
# Save the first heatmap
save_heatmap(HM_Met, "Heatmap_Metrics_Percentages.png", HM_Met_percent_char)
# Second Heatmap - Confusion Matrix Metrics
HM_Met <- All_Metric[, -c(1:7)]
rownames(HM_Met) <- All_Metric[, 1]
rownames(HM_Met) <- gsub(" \\(Combined Test Data\\)", "", rownames(HM_Met))
HM_Met <- as.matrix(HM_Met)
HM_Met <- round(HM_Met, 1)
# Save the second heatmap
save_heatmap(HM_Met, "Heatmap_Confusion_Matrix_Metrics.png", HM_Met)
# Get the list of CSV files in the working directory
csv_files <- list.files(pattern = "\\.csv$")
# Loop through each CSV file and read it into a data frame
for (file in csv_files) {
# Extract the name of the data frame from the file name
df_name <- sub(".csv$", "", file)
# Read the CSV file into a data frame
assign(df_name, read.csv(file))
}
# Define the desired columns
desired_columns <- c("Model", "Accuracy", "Precision", "Recall", "F1_Score", "AUC", "Neg_Pred_Value", "TP", "TN", "FN", "FP")
# Function to subset data frames to include only desired columns
subset_columns <- function(df, columns) {
# Check if all desired columns are present in the data frame
if (all(columns %in% colnames(df))) {
return(df[, columns, drop = FALSE])
} else {
# Return a message if some columns are missing
warning("Some columns are missing in the data frame")
return(df) # Return the original data frame if columns are missing
}
}
# Subset each data frame to keep only the desired columns
logistic_model_metrics <- subset_columns(logistic_model_metrics, desired_columns)
lasso_model_metrics <- subset_columns(lasso_model_metrics, desired_columns)
svm_model_metrics <- subset_columns(svm_model_metrics, desired_columns)
en_model_metrics <- subset_columns(en_model_metrics, desired_columns)
rf_model_metrics <- subset_columns(rf_model_metrics, desired_columns)
mda_model_metrics <- subset_columns(mda_model_metrics, desired_columns)
neural_network_metrics <- subset_columns(neural_network_metrics, desired_columns)
Meta_Model_metrics <- subset_columns(Meta_Model_metrics_test, desired_columns)
# Combine the subsetted data frames into one data frame
All_Metric <- rbind(
logistic_model_metrics,
lasso_model_metrics,
svm_model_metrics,
en_model_metrics,
rf_model_metrics,
mda_model_metrics,
neural_network_metrics,
Meta_Model_metrics
)
write.csv(All_Metric, "All_Model_Metrics.csv", row.names = FALSE)
# Define a folder to save the heatmaps
output_folder <- "Heatmaps"
if (!dir.exists(output_folder)) {
dir.create(output_folder)
}
# Function to save heatmap to file
save_heatmap <- function(matrix_data, file_name, cellnote_data) {
# Define the file path
file_path <- file.path(output_folder, file_name)
# Open a graphics device to save the plot
png(file_path, width = 800, height = 600)
# Plot heatmap
heatmap.2(matrix_data, Rowv = NA, Colv = NA, dendrogram = "none", trace = "none",
col = rev(colorRampPalette(c("red","white", "turquoise"))(256)), scale = "column", key = TRUE, keysize = 1.5,
key.title = NA, density.info = "none", cexRow = 0.8, cexCol = 0.8,
margins = c(8, 8), cellnote = cellnote_data, notecol = "black")
# Close the graphics device
dev.off()
}
# First Heatmap - Metrics in Percentages
HM_Met <- All_Metric[, -c(1,8:11)]
rownames(HM_Met) <- All_Metric[, 1]
rownames(HM_Met) <- gsub(" \\(Combined Test Data\\)", "", rownames(HM_Met))
HM_Met <- as.matrix(HM_Met)
HM_Met_percent <- HM_Met * 100
HM_Met_percent_rounded <- round(HM_Met_percent, 1)
HM_Met_percent_char <- matrix(paste0(HM_Met_percent_rounded, "%"), nrow = nrow(HM_Met_percent_rounded))
# Save the first heatmap
save_heatmap(HM_Met, "Heatmap_Metrics_Percentages.png", HM_Met_percent_char)
# Second Heatmap - Confusion Matrix Metrics
HM_Met <- All_Metric[, -c(1:7)]
rownames(HM_Met) <- All_Metric[, 1]
rownames(HM_Met) <- gsub(" \\(Combined Test Data\\)", "", rownames(HM_Met))
HM_Met <- as.matrix(HM_Met)
HM_Met <- round(HM_Met, 1)
# Save the second heatmap
save_heatmap(HM_Met, "Heatmap_Confusion_Matrix_Metrics.png", HM_Met)
View(logistic_model_metrics)
